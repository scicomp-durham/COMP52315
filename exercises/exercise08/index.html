<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Loop tiling for matrix–matrix multiplication #  In Exercise 7, we looked at the effect of loop tiling schemes to increase the throughput of matrix transposition. Now we are going to look at the throughput of loop tiling for matrix–matrix multiplication. The matrix-matrix multiplication code we will use provides contains different variants: a naive triple loop, a tiled version of the triple loop, and a tiled version that manually packs local buffers."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Loop tiling for matrix–matrix multiplication"><meta property="og:description" content="Loop tiling for matrix–matrix multiplication #  In Exercise 7, we looked at the effect of loop tiling schemes to increase the throughput of matrix transposition. Now we are going to look at the throughput of loop tiling for matrix–matrix multiplication. The matrix-matrix multiplication code we will use provides contains different variants: a naive triple loop, a tiled version of the triple loop, and a tiled version that manually packs local buffers."><meta property="og:type" content="article"><meta property="og:url" content="https://scicomp-durham.github.io/COMP52315/exercises/exercise08/"><meta property="article:modified_time" content="2023-02-08T02:19:00+00:00"><title>Loop tiling for matrix–matrix multiplication | COMP52315 – Performance Engineering, Vectorisation and GPU Programming</title><link rel=icon href=/COMP52315/favicon.svg type=image/x-icon><link rel=stylesheet href=/COMP52315/book.min.0cb0b7d6a1ed5d0e95321cc15edca4d6e9cc406149d1f4a3f25fd532f6a3bb38.css integrity="sha256-DLC31qHtXQ6VMhzBXtyk1unMQGFJ0fSj8l/VMvajuzg="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]})});</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/COMP52315/logo.svg alt=Logo><h2><a href=/COMP52315>COMP52315 – Performance Engineering, Vectorisation and GPU Programming</a></h2></div><ul><li><span>Course resources</span><ul><li><a href=/COMP52315/setup/contact/>Contact details</a></li><li><a href=/COMP52315/setup/hamilton/>Hamilton accounts</a></li><li><a href=/COMP52315/setup/configuration/>ssh configuration</a></li><li><a href=/COMP52315/setup/unix/>Unix resources</a></li></ul></li><li><a href=/COMP52315/journal/>Journal</a></li><li><a href=/COMP52315/exercises/>Exercises</a><ul></ul></li><li><a href=/COMP52315/notes/>Notes</a><ul></ul></li><li><a href=/COMP52315/resources/>Further resources</a></li><li><a href=/COMP52315/acknowledgements/>Acknowledgements</a></li><li><a href=/COMP52315/past-editions/>Past editions</a><ul><li><a href=/COMP52315/past-editions/2020-21/>Edition 2020/2021</a><ul></ul></li><li><a href=/COMP52315/past-editions/2021-22/>Edition 2021/2022</a><ul></ul></li></ul></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/COMP52315/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Loop tiling for matrix–matrix multiplication</strong>
<label for=toc-control><img src=/COMP52315/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#loop-tiling-for-matrixmatrix-multiplication>Loop tiling for matrix–matrix multiplication</a><ul><li><a href=#compiling-the-code>Compiling the code</a></li><li><a href=#compare-the-variants>Compare the variants</a></li><li><a href=#inspecting-optimisation-reports>Inspecting optimisation reports</a></li><li><a href=#the-effects-of-tiling-on-memory-movement>The effects of tiling on memory movement</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=loop-tiling-for-matrixmatrix-multiplication>Loop tiling for matrix–matrix multiplication
<a class=anchor href=#loop-tiling-for-matrixmatrix-multiplication>#</a></h1><p>In <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise07/>Exercise 7</a>, we looked at the
effect of loop tiling schemes to increase the throughput of matrix
transposition. Now we are going to look at the throughput of loop
tiling for matrix–matrix multiplication. The <a href=https://scicomp-durham.github.io/COMP52315/code/exercise08/gemm.c>matrix-matrix
multiplication code</a> we will use
provides contains different variants: a naive triple loop, a tiled
version of the triple loop, and a tiled version that manually
packs local buffers.</p><h2 id=compiling-the-code>Compiling the code
<a class=anchor href=#compiling-the-code>#</a></h2><p>We will be using the intel compiler to build this code. After
logging in to Hamilton and downloading the <code>gemm.c</code> code, we need
to load the compiler with</p><pre><code>module load intel/2022.2
</code></pre><p>The code can be compiled with <code>icx -O3 -xHOST -o gemm gemm.c</code>.</p><h2 id=compare-the-variants>Compare the variants
<a class=anchor href=#compare-the-variants>#</a></h2><p>You can run the different implemented variants with <code>./gemm N VARIANT</code>
where <code>N</code> is the matrix size and <code>VARIANT</code> is one of <code>BASIC</code>, <code>TILED</code>,
or <code>TILEDPACKED</code>.</p><p>For the <code>TILED</code> and <code>TILEDPACKED</code> variants, the matrix size must be a
multiple of the tile size (which is 64 by default).</p><blockquote class=exercise><h3>Exercise</h3><span>Run the code with matrix sizes from 64 up to 2048.</span></blockquote><blockquote class=question><h3>Question</h3><span>Which version performs the best?</span></blockquote><h2 id=inspecting-optimisation-reports>Inspecting optimisation reports
<a class=anchor href=#inspecting-optimisation-reports>#</a></h2><p>You probably noticed that the <code>TILEDPACKED</code> variant
performed very badly. Before measuring anything, we can look at more
detailed output from the compiler to see if we spot anything
suspicious.</p><p>The Intel compiler can provide excellent diagnostics on what it was
doing when compiling code. Run the compile command again, this time
with</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-sh data-lang=sh>icx -O3 -xHOST -qopt-report<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span> -qopt-report-file<span style=color:#f92672>=</span>no-simd-reduction.txt -o gemm gemm.c
</code></pre></div><p>Look in the resulting <code>no-simd-reduction.txt</code> file and search for
<code>tiled_packed_gemm</code> (the name of the routine that performs worse
than expected).</p><blockquote class=question><h3>Question</h3><span>Do you see anything in the optimisation report that stands out as
interesting?</span></blockquote><p>In this case, it seems that we need to give the compiler a hint as to
how to proceed. It did not vectorise the inner loop because it
couldn&rsquo;t prove that it was safe to do so. However, we know it is safe,
so I&rsquo;ve added some annotations to the relevant loop. Instead of having</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#111>p</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>p</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>TILESIZE</span><span style=color:#111>;</span> <span style=color:#111>p</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
  <span style=color:#111>c</span><span style=color:#111>[</span><span style=color:#111>j_</span><span style=color:#f92672>*</span><span style=color:#111>ldc</span> <span style=color:#f92672>+</span> <span style=color:#111>i_</span><span style=color:#111>]</span> <span style=color:#f92672>+=</span> <span style=color:#111>apack</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>]</span> <span style=color:#f92672>*</span> <span style=color:#111>bpack</span><span style=color:#111>[</span><span style=color:#111>j</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>];</span>
<span style=color:#111>}</span>
</code></pre></div><p>I use <a href=https://www.openmp.org>OpenMP</a> pragma annotations to instruct
the compiler to vectorise the loop</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>double</span> <span style=color:#111>c_</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span>
<span style=color:#75715e>#pragma omp simd reduction (+: c_)
</span><span style=color:#75715e></span><span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#111>p</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>p</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>TILESIZE</span><span style=color:#111>;</span> <span style=color:#111>p</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
  <span style=color:#111>c_</span> <span style=color:#f92672>+=</span> <span style=color:#111>apack</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>]</span> <span style=color:#f92672>*</span> <span style=color:#111>bpack</span><span style=color:#111>[</span><span style=color:#111>j</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>];</span>
<span style=color:#111>}</span>
<span style=color:#111>c</span><span style=color:#111>[</span><span style=color:#111>j_</span><span style=color:#f92672>*</span><span style=color:#111>ldc</span> <span style=color:#f92672>+</span> <span style=color:#111>i_</span><span style=color:#111>]</span> <span style=color:#f92672>+=</span> <span style=color:#111>c_</span><span style=color:#111>;</span>
</code></pre></div><blockquote class=exercise><h3>Exercise</h3><span>Try compiling again, this time adding <code>-DSIMD_REDUCTION</code> to the
compile line (and changing the output file for the optimisation report
to <code>simd-reduction.txt</code></span></blockquote><blockquote class=question><h3>Question</h3><span><p>Look at the new optimisation report and see what the compiler reports
this time.</p><p>Did it manage to vectorise the loop?</p></span></blockquote><blockquote class=exercise><h3>Exercise</h3><span>Benchmark this new version of the <code>TILEDPACKED</code> variant using the same
set of matrix sizes as before.</span></blockquote><blockquote class=question><h3>Question</h3><span>Do you observe any change in the performance?</span></blockquote><h2 id=the-effects-of-tiling-on-memory-movement>The effects of tiling on memory movement
<a class=anchor href=#the-effects-of-tiling-on-memory-movement>#</a></h2><p>As usual, this example is also annotated with likwid markers. We&rsquo;ll
use <code>likwid-perfctr</code> to measure the effect of loop tiling on the total
<em>data movement</em> and measured <em>arithmetic intensity</em> for a large
matrix. We&rsquo;ll need to recompile with likwid enabled for this, so
<code>module load likwid/5.2.0</code> and recompile, adding <code>-DLIKWID_PERFMON -llikwid</code> to the compilation flags.</p><blockquote class=exercise><h3>Exercise</h3><span>Measure the memory and floating point performance for the three
different variatnts using \(N = 3072\) using the <code>MEM_DP</code> group.</span></blockquote><blockquote class=question><h3>Question</h3><span><p>What do you observe in terms of operational intensity and total
volume of data moved from main memory?</p><p>Can you relate this to the simple model we discussed?</p></span></blockquote></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/scicomp-durham/COMP52315/commit/5e994206d6719c797436471e6da757e835e3610b title="Last modified by Massimiliano Fasi | February 8, 2023" target=_blank rel=noopener><img src=/COMP52315/svg/calendar.svg class=book-icon alt=Calendar>
<span>February 8, 2023</span></a></div><div><a class="flex align-center" href=https://github.com/scicomp-durham/COMP52315/edit/main/site/content//exercises/exercise08.md target=_blank rel=noopener><img src=/COMP52315/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash;2023 <a href=mailto:lawrence@wence.uk>Lawrence Mitchell</a>, <a href=mailto:massimiliano.fasi@durham.ac.uk>Massimiliano Fasi</a>, and <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/COMP52315/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#loop-tiling-for-matrixmatrix-multiplication>Loop tiling for matrix–matrix multiplication</a><ul><li><a href=#compiling-the-code>Compiling the code</a></li><li><a href=#compare-the-variants>Compare the variants</a></li><li><a href=#inspecting-optimisation-reports>Inspecting optimisation reports</a></li><li><a href=#the-effects-of-tiling-on-memory-movement>The effects of tiling on memory movement</a></li></ul></li></ul></nav></aside></main></body></html>