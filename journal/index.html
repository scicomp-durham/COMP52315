<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Journal #  Slides that will be used in the lectures. A link to the Panopto recording, if available, as well as a short summary of what was discussed, will follow after the session. If you think you should have access to the recordings but you don&rsquo;t, please get in touch.
  Session 1: Slides – Notes – Exercise 1 – Audio
The Encore capture system had some troubles, thus only the audio recording of the session is available."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Journal"><meta property="og:description" content="Journal #  Slides that will be used in the lectures. A link to the Panopto recording, if available, as well as a short summary of what was discussed, will follow after the session. If you think you should have access to the recordings but you don&rsquo;t, please get in touch.
  Session 1: Slides – Notes – Exercise 1 – Audio
The Encore capture system had some troubles, thus only the audio recording of the session is available."><meta property="og:type" content="article"><meta property="og:url" content="https://scicomp-durham.github.io/COMP52315/journal/"><meta property="article:modified_time" content="2023-02-08T02:19:00+00:00"><title>Journal | COMP52315 – Performance Engineering, Vectorisation and GPU Programming</title><link rel=icon href=/COMP52315/favicon.svg type=image/x-icon><link rel=stylesheet href=/COMP52315/book.min.0cb0b7d6a1ed5d0e95321cc15edca4d6e9cc406149d1f4a3f25fd532f6a3bb38.css integrity="sha256-DLC31qHtXQ6VMhzBXtyk1unMQGFJ0fSj8l/VMvajuzg="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]})});</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/COMP52315/logo.svg alt=Logo><h2><a href=/COMP52315>COMP52315 – Performance Engineering, Vectorisation and GPU Programming</a></h2></div><ul><li><span>Course resources</span><ul><li><a href=/COMP52315/setup/contact/>Contact details</a></li><li><a href=/COMP52315/setup/hamilton/>Hamilton accounts</a></li><li><a href=/COMP52315/setup/configuration/>ssh configuration</a></li><li><a href=/COMP52315/setup/unix/>Unix resources</a></li></ul></li><li><a href=/COMP52315/journal/ class=active>Journal</a></li><li><a href=/COMP52315/exercises/>Exercises</a><ul></ul></li><li><a href=/COMP52315/notes/>Notes</a><ul></ul></li><li><a href=/COMP52315/resources/>Further resources</a></li><li><a href=/COMP52315/acknowledgements/>Acknowledgements</a></li><li><a href=/COMP52315/past-editions/>Past editions</a><ul><li><a href=/COMP52315/past-editions/2020-21/>Edition 2020/2021</a><ul></ul></li><li><a href=/COMP52315/past-editions/2021-22/>Edition 2021/2022</a><ul></ul></li></ul></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/COMP52315/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Journal</strong>
<label for=toc-control><img src=/COMP52315/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#journal>Journal</a></li></ul></nav></aside></header><article class=markdown><h1 id=journal>Journal
<a class=anchor href=#journal>#</a></h1><p>Slides that will be used in the lectures. A link to the Panopto
recording, if available, as well as a short summary of what was
discussed, will follow after the session. If you think you should have
access to the recordings but you don&rsquo;t, please <a href=%28mailto:massimiliano.fasi@durham.ac.uk%29>get in
touch</a>.</p><ul><li><p><strong>Session 1</strong>:
<a href=https://scicomp-durham.github.io/COMP52315/lecture-slides/01.pdf>Slides</a> –
<a href=https://scicomp-durham.github.io/COMP52315/notes/introduction/>Notes</a> –
<a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise01/>Exercise 1</a> –
<a href="https://durham.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=931d06c3-113f-4e06-b03e-af82009523dc">Audio</a></p><p>The Encore capture system had some troubles, thus only the audio
recording of the session is available.</p><p>We introduced some ideas of computer architecture and talked about the
motivation for the course. There is a focus on trying to build
predictive models for the speed that code runs at.</p><p>We finished by working through the <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise01/>Exercise 1</a>. We will discuss the results
in the next session.</p></li><li><p><strong>Session 2</strong>:
<a href=https://scicomp-durham.github.io/COMP52315/lecture-slides/02.pdf>Slides</a> –
<a href=https://scicomp-durham.github.io/COMP52315/notes/memory/>Notes</a> –
<a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise02/>Exercise 2</a> –
<a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise03/>Exercise 3</a> –
<a href="https://durham.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=c477e919-b55c-422b-b799-af870094e658">Audio</a></p><p>The Encore capture system still has troubles, and there is a chance it
will keep having troubles until the end of the submodule. I&rsquo;ve decided
to put a link to the audio recording, should anyone find them useful.</p><p>We started by looking at the results of <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise01/>Exercise 1</a>. We noticed that the performance drops
as the size of the array we use in the benchmark increases, and we
identified three plateaus.</p><p>To justify these results, we discussed the fact that the memory is
divided into several levels (L1, L2, L3 caches, and main memory) and
that these levels have very different sizes and performance levels.</p><p>We then focused on the cache memory and discussed the organisation of
direct mapped and associative cache. We briefly mentioned $k$-way
associative caches.</p><p>We finished by working through <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise02/>Exercise 2</a> and <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise03/>Exercise 3</a>. We will discuss the results in the
next session.</p></li><li><p><strong>Session 3</strong>:
<a href=https://scicomp-durham.github.io/COMP52315/lecture-slides/03.pdf>Slides</a> –
<a href=https://scicomp-durham.github.io/COMP52315/notes/roofline/>Notes</a> –
<a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise04/>Exercise 4</a> –
<a href="https://durham.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=21ef9a68-e27f-448d-bd47-af8900946d7b">Audio</a> –
<a href=https://dl.acm.org/doi/pdf/10.1145/1498765.1498785>Paper</a></p><p>Still no luck with the Encore capture system, but the audio is
available.</p><p>We began the session by analysing the results of <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise02/>Exercise 2</a> and <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise03/>Exercise 3</a>. We focused in particular on <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise02/>Exercise
2</a>, of which we gave a rather
detailed interpretation by means of pen-and-paper calculations. You
can find these at towards the end of the <a href=https://scicomp-durham.github.io/COMP52315/lecture-slides/02.pdf>slides for Session 2</a>.</p><p>Next, we introduced the roofline model, discussing the key parameters
we need to estimate. Of these, two (peak floating-point performance
and main memory bandwidth) depend on the hardware and one (operational
intensity) on the code we are measuring. We started to how these
parameters can be estimated, either by looking at spec sheets or
source code, or by direct measurement. We will give more details on
the methods based on measurement in the rest of the course.</p><p>We concluded by collecting the data necessary to obtain a roofline
model for the performance of a simple code computing matrix–vector
multiplication. This was the subject of <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise04/>Exercise 4</a>.</p><p>In preparation for the next session, please have a look at the
<a href=https://dl.acm.org/doi/pdf/10.1145/1498765.1498785>article</a> in which
roofline models were introduced, and note down any comments or
questions you might have. Throughout the paper, which was published 14
years ago, the authors (Williams, Waterman, and Patterson) make a
number of predictions regarding the evolution of computing. You can
try to think whether and to what degree they came to pass.</p></li><li><p><strong>Session 4</strong>:
<a href=https://scicomp-durham.github.io/COMP52315/lecture-slides/04.pdf>Slides</a> –
<a href=https://scicomp-durham.github.io/COMP52315/notes/measurements/>Notes</a> –
<a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise05/>Exercise 5</a></p><p>The Encore capture system was faulty this time, so no recording of the
live session is available.</p><p>We spent most of the session discussing the paper by Williams,
Waterman, and Patterson. We then moved on to the slides and started
discussing performance counters.</p><p>We concluded the session by working through <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise05/>Exercise 5</a>: we used <code>likwid-perfctr</code> to collect
performance measurements on an implementation of the STREAM TRIAD
benchmark that uses <code>likwid</code>'s Marker API.</p></li><li><p><strong>Session 5</strong>:
<a href=https://scicomp-durham.github.io/COMP52315/lecture-slides/05.pdf>Slides</a> –
<a href=https://scicomp-durham.github.io/COMP52315/notes/measurements/>Notes</a> –
<a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise06/>Exercise 6</a> –
<a href="https://durham.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=8b58f649-6a44-4b56-a979-af9000968342">Recording</a></p><p>The session was dedicated to profiling. We discussed the differences
between sampling and instrumentation. We then focused in detail at the
GNU Profiler, which uses a hybrid of the two approaches. We discussed
the capabilities of the tool, and looked in particular at the three
types of output the tool can produce: flat profile, call graph, and
annotated source code.</p><p>We concluded the session by profiling some code with <code>gprof</code> and
instrumenting it to collect performance measurements with
<code>likwid-perfctr</code>.
In <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise06/>Exercise 6</a> we looked at
profiling and measuring the performance of some simple C code and
of the <code>miniMD</code> application.</p><p>There were some issues with the exercises. Thank you Yash for finding
out how to produce a call graph with <code>gprof</code> when the executable is
compiled with <code>-O3</code>. I have updated the exercise to reflect that.</p></li><li><p><strong>Session 6</strong>:
<a href=https://scicomp-durham.github.io/COMP52315/lecture-slides/06.pdf>Slides</a> –
<a href=https://scicomp-durham.github.io/COMP52315/notes/tiling/>Notes</a> –
<a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise07/>Exercise 7</a> –
<a href="https://durham.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7a952d80-e5f4-485f-b348-af9500954751">Recording</a></p><p>In this session, we looked at cache effects in matrix transposition.
We began by developing a simple performance model for this operation,
which requires memory accesses but no computation, and we saw that the
performance of a naive implementation is much worse than our model
would predict. We argued that this is due to a poor usage of the
cache, as the algorithm implemented in a naive way cannot exploit
cache locality when the matrices are large.</p><p>We then discussed how cache utilization can be improved by combining
<em>strip mining</em>, which splits large loops into several small chunks of
fixed size, and <em>loop reordering</em>. We argued that this technique is
most useful to address the poor performance of nested loops, and we
used our model to make sense of it.</p><p>In <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise07/>Exercise 7</a>, we compared
the performance of two implementation of matrix transposition, a naive
one based on nested loops and a more advanced one supporting tiling,
and our experiments mostly confirmed our expectations. We also
stumbled over a well-known but quite surprising phenomenon when trying
to transpose large matrices whose size is a power of 2 (in our
examples, this behaviour was clearly visible for matrices of size 4096
$\times$ 4096 and multiples thereof.)</p></li><li><p><strong>Session 7</strong>:
<a href=https://scicomp-durham.github.io/COMP52315/lecture-slides/07.pdf>Slides</a> –
<a href=https://scicomp-durham.github.io/COMP52315/notes/tiling/>Notes</a> –
<a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise08/>Exercise 8</a> –
<a href="https://durham.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=f94eec2d-42ca-4981-be8e-af900095a536">Recording</a></p><p>In this session, we kept discussing the use of cache memory for matrix
operations, focusing on matrix–matrix multiplication. This operation
is more complicated than matrix transposition because it involves
three matrices, all of which have to be stored in cache to guarantee
reuse.</p><p>In <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise08/>Exercise 8</a>, we tried to
compare three different algorithms for matrix—matrix multiplication: a
naive variant, one that uses tiles, and one that combines tiling and
packing. There were some issues with the compilation command, which
have hopefully been fixed in the updated version of the exercise.</p><ul><li>I had been testing the code with a different version of the Intel
compiler (<code>icc</code> rather than <code>icx</code>), which was much less aggressive
in its use of vectorisation. This is not the default compiler for
the <code>intel/2022.2</code> module that is the latest on Hamilton.</li><li>Some of the flags (<code>-xHOST</code> in particular), which were accepted by
<code>icc</code>, are not accepted by <code>icx</code> and cannot be used any longer.</li></ul></li><li><p><strong>Session 8</strong>:
<a href=https://scicomp-durham.github.io/COMP52315/lecture-slides/08.pdf>Slides</a> –
<a href=https://scicomp-durham.github.io/COMP52315/notes/tiling/>Notes</a> –
<a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise09/>Exercise 9</a> –
<a href="https://durham.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=979428a6-2dba-43cb-9dc4-af9c0094e16f">Recording</a></p><p>We started the session with an update on the results of <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise03/>Exercise 3</a>. We looked at the correct setup for the
exercise and we tried to make sense of the results.</p><p>We then moved on to vectorisation, which was the main topic for this final
session of the submodule. After a general introduction on the data parallelism
paradigm, we focused on the practical use of vectorisation in C and C++,
looking at code the compiler can vectorise automatically and at ways we can
help it with compiler- and OpenMP-specific <code>#pragma</code> directives.</p><p>In <a href=https://scicomp-durham.github.io/COMP52315/exercises/exercise09/>Exercise 9</a>, we tried to vectorise
the BLIS DGEMM micro-kernel using only compiler flags.</p></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/scicomp-durham/COMP52315/commit/5e994206d6719c797436471e6da757e835e3610b title="Last modified by Massimiliano Fasi | February 8, 2023" target=_blank rel=noopener><img src=/COMP52315/svg/calendar.svg class=book-icon alt=Calendar>
<span>February 8, 2023</span></a></div><div><a class="flex align-center" href=https://github.com/scicomp-durham/COMP52315/edit/main/site/content//journal.md target=_blank rel=noopener><img src=/COMP52315/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash;2023 <a href=mailto:lawrence@wence.uk>Lawrence Mitchell</a>, <a href=mailto:massimiliano.fasi@durham.ac.uk>Massimiliano Fasi</a>, and <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/COMP52315/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#journal>Journal</a></li></ul></nav></aside></main></body></html>