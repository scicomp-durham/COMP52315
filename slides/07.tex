% -*- TeX-engine: luatex -*-
\documentclass[dvipsnames,presentation,aspectratio=169,14pt]{beamer}
\usepackage{hastingstheme}
\input{lecturer.tex}


% \usepackage{template}
% \input{setup-lawrence}
% \renewcommand{\sessionnumber}{5}
% \renewcommand{\sessiontitle}{Cache blocking/tiling}
% \usepackage{tikz}

% \usetikzlibrary{fit,positioning,Cal}
\usetikzlibrary{matrix,positioning}
\usepackage{pgfplotstable}
% \usetikzlibrary{pgfplots.groupplots}
\usepackage{booktabs}

\date{}

\begin{document}

\title{\firasemibold\color{White}%
  {\fontsize{20}{0}\selectfont SESSION 7\\
    \fontsize{34}{34}\selectfont Matrix--matrix\\multiplication\par}}
\titleslide


\begin{frame}[fragile]
  \frametitle{Matrix--matrix multiplication}
  Given $n$-by-$n$ matrices $A$ and $B$, we can compute $C = AB$
  \begin{equation*}
    C_{ij} \gets C_{ij } + \sum_k A_{ik} B_{kj}
  \end{equation*}
  with
\begin{minted}[fontsize=\normalsize]{c}
          for (int i = 0; i < n; i++)
            for (int j = 0; j < n; j++)
              for (int k = 0; k < n; k++)
                C[i*n + j] += A[i*n + k] * B[k*n + j];
\end{minted}

  % Same story here (or at least it was in the 90s!).
\end{frame}

\newcommand{\thebigslide}[2]{%
\begin{frame}
  \frametitle{Two-level memory model (``fast'' and ``slow'')}

  \vskip 3pt

  \begin{columns}
    \begin{column}{0.5\textwidth}
      \begin{itemize}[wide=5pt,itemsep=8pt]
      \item $\textcolor{MidnightBlue}{m}$: \# data elements moved
      \item $\textcolor{MidnightBlue}{f}$: \# flops
      \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
      \begin{itemize}[wide=2pt,itemsep=8pt]
      \item $\textcolor{BrickRed}{t_m}$: time per memory access
      \item $\textcolor{BrickRed}{t_f} \ll t_m$ time per flop
      \end{itemize}
    \end{column}
  \end{columns}
  \vskip 13pt

  \begin{center}
    $\textcolor{MidnightBlue}{q =: f/m}$ average flops per slow memory access
  \end{center}

  \vskip 5pt
  \hrule
  \vskip 5pt

  \begin{columns}
    \begin{column}{0.45\textwidth}
      \onslide<#1->{%
      \centering Minimum time to solution
      \begin{equation*}
        \textcolor{BrickRed}{t_f} \cdot \textcolor{MidnightBlue}{f}%
        \vphantom{\frac{t_M}{t_{f}}}
      \end{equation*}}
    \end{column}
    \hfill
    \vrule
    \hfill
    \begin{column}{0.45\textwidth}
      \onslide<#2->{%
      \centering Typical time to solution
      \begin{equation*}
        \textcolor{MidnightBlue}{f} \; \textcolor{BrickRed}{t_f} +
        \textcolor{MidnightBlue}{m}
        \;  \textcolor{BrickRed}{t_m} =
        \textcolor{MidnightBlue}{f}\; \textcolor{BrickRed}{t_f}
        \left(
          \mathsf{1} +
          \textcolor{BrickRed}{\frac{t_m}{t_f}} \cdot
          \textcolor{MidnightBlue}{\frac{\mathsf{1}}{q}}
        \right)
      \end{equation*}}
    \end{column}
  \end{columns}

  \vskip 5pt
  \hrule
  \vskip 15pt

  \begin{center}
    \textcolor{BrickRed}{hardware} \qquad \textcolor{MidnightBlue}{software}
  \end{center}
\end{frame}}

\thebigslide{2}{3}

\begin{frame}[fragile]
  \frametitle{Na\"ive matrix-multiply}
  \begin{onlyenv}<1>
\begin{minted}[fontsize=\normalsize]{c}
 for (int i = 0; i < n; i++)
   for (int j = 0; j < n; j++)
     for (int k = 0; k < n; k++)
       C[i*n + j] = C[i*n + j] + A[i*n + k] * B[k*n + j];
\end{minted}
    \vskip 10pt

    \begin{itemize}
    \item $\mathsf 2n^\mathsf{3} = \mathcal{O}(n^\mathsf{3})$ flops
      and $\mathsf{3\cdot 8 n^2}$ bytes of memory
    \item $\textcolor{MidnightBlue}{q}$ potentially $\mathcal{O}(n)$,
      arbitrarily large for large $n$
    \end{itemize}

    \begin{center}
      \begin{tikzpicture}[nodes in empty cells,
        inner sep=0cm,
        nodes={minimum width=0.55cm, minimum height=0.55cm, text
          height=0.35cm, text depth=0.15cm},
        row sep=-\pgflinewidth, column sep=-\pgflinewidth]
        \matrix(Cout)[draw, matrix of nodes]
        {
          & & & \\
          & & & \\
          &|[fill=red!50]| $C_{ij}$ & & \\
          & & & \\
        };
        \node[right=0cm of Cout] (eq) {$=$};
        \matrix(Cin)[right=0cm of eq, draw, matrix of nodes]
        {
          & & & \\
          & & & \\
          &|[fill=red!50]| $C_{ij}$ & & \\
          & & & \\
        };
        \node[right=0cm of Cin] (plus) {$+$};
        \matrix(Ain)[right=0cm of plus, draw, matrix of nodes,
        row 3/.style={nodes={fill=red!50}}]
        {
          & & & \\
          & & & \\
          & $A_{i}$ & & \\
          & & & \\
        };
        \node[right=0cm of Ain] (times) {$\times$};
        \matrix(Bin)[right=0cm of times, draw, matrix of nodes,
        column 2/.style={nodes={fill=red!50}}]
        {
          &  & & \\
          &  & & \\
          & $B_{j}$ & & \\
          & & & \\
        };
      \end{tikzpicture}
    \end{center}
  \end{onlyenv}
  \begin{onlyenv}<2>
\begin{minted}[fontsize=\normalsize, mathescape=true]{c}
for (int i = 0; i < n; i++)
  // Read row $i$ of $A$ into fast memory
  for (int j = 0; j < n; j++)
    // Read $C_{ij}$ into fast memory
    // Read column $j$ of $B$ into fast memory
    for (int k = 0; k < n; k++)
      C[i*n + j] = C[i*n + j] + A[i*n + k] * B[k*n + j];
      // Write $C_{ij}$ back to slow memory
\end{minted}
  \end{onlyenv}
\end{frame}

\begin{frame}
  \frametitle{Number of slow memory references}
  \begin{align*}
    m &= \mathsf{n^3} &\text{each column of $B$ is read $n$ times}\\
      &+ \mathsf{n^2} &\text{each row of $A$ is read once}\\
      &+ \mathsf{2n^2} & \text{each entry of $C$ is read once and
                         written once}\\
      &= \mathsf{(n^3 + 3n^2)}
  \end{align*}
  Hence
  \begin{equation*}
    \mathsf{\lim_{n\to \infty} \textcolor{MidnightBlue}{q}
      = \frac{\textcolor{MidnightBlue}{f}}{\textcolor{MidnightBlue}{m}}
      = \frac{2n^3}{(n^3 + 3n^2)}
      = 2}
  \end{equation*}
\end{frame}

\thebigslide{1}{1}

\begin{frame}
  \frametitle{From model to prediction}
  \begin{itemize}
  \item For three nested loops, predicted \emph{typical} time to solution is:
    \begin{equation*}
      T =
      \textcolor{MidnightBlue}{f}\; \textcolor{BrickRed}{t_f}
      \left(
        \mathsf{1} +
        \frac{\textcolor{BrickRed}{t_m}}
        {\mathsf{\textcolor{MidnightBlue}{2}}\;\textcolor{BrickRed}{t_f}}
      \right)
      \end{equation*}

    \item<2-> Memory \emph{latency} of about 200 cycles per cache line (8 doubles)
      \pause
    \item<3-> Approximating $\mathsf{\textcolor{BrickRed}{t_m} \approx 200 / 8 = 25}$, and say $\mathsf{\textcolor{BrickRed}{t_f} = 1}$:
      \begin{equation*}
        \mathsf{T =
          \textcolor{MidnightBlue}{f}\; \textcolor{BrickRed}{t_f}
          \left(1 + \frac{25}{2}\right) =
          13.5 \; \textcolor{MidnightBlue}{f}\; \textcolor{BrickRed}{t_f}}
      \end{equation*}
    \item<3-> \structure{Estimate:} Maximum 7\% flop peak.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Measurement}
  \begin{itemize}[itemsep=8pt]
    \small
    % \item Single core Intel i5-8259U.
  \item 2 4-wide FMAs per cycle $\Rightarrow$ 16 DP Flops/cycle
  \item Peak is $\mathsf{3.6 \cdot 16 = 57.6}$ GFlops/s $\Rightarrow$
    model predicts 4.03 GFlops/s
  \end{itemize}
  \vskip 15pt
  \pause
  \begin{center}
    \begin{tikzpicture}
      \pgfplotstableset{create on use/flops/.style={
          create col/expr={1e-9*\thisrow{FLOP}/\thisrow{TIME}}}};
      \begin{axis}[
        height=6cm,
        width = 14cm,
        xlabel near ticks,
        xlabel={\small Matrix size},
        ylabel near ticks,
        ylabel={\small GFlop/s},
        legend style={fill=bgcolor, font={\small}}]
        \addplot+ [mark repeat=5] table[x=N, y=flops] {../figures/gemm-basic.dat};
        \addlegendentry{Triple loop};
        \addplot+ [domain=0:3072, mark=none, line width=2] {4.03};
        \addlegendentry{Model};
      \end{axis}
    \end{tikzpicture}
  \end{center}
\end{frame}

  % \begin{itemize}
  % \item Problem is that we move rows and columns into fast memory, and
  %   then evict them
  % \item Need way of keeping the loaded data in fast memory as long as
  %   possible.
  % \item[$\Rightarrow$] tile iterations
  % \end{itemize}

\begin{frame}[fragile]
  \frametitle{How to improve reuse?}
  \begin{onlyenv}<1>
\begin{minted}[fontsize=\small, mathescape=true]{c}
// Treat $A, B, C \in \left(\mathbb{R}^{b \times b}\right)^{N \times N}$
// $N \times N$ matrices where each entry is a $b \times b$ matrix.
for (int i = 0; i < N; i++)
  for (int j = 0; j < N; j++)
    // Read block $C_{ij}$ into fast memory
    for (int k = 0; k < n; k++)
      // Read block $A_{ik}$ into fast memory
      // Read block $B_{kj}$ into fast memory
      // Do matrix multiply on the blocks
      C[i*N + j] = C[i*N + j] + A[i*N + k] * B[k*N + j];
      // Write block $C_{ij}$ back to slow memory


\end{minted}
  \end{onlyenv}
  \begin{onlyenv}<2>
\begin{minted}[fontsize=\small, mathescape=true]{c}
// Treat $A, B, C \in \left(\mathbb{R}^{b \times b}\right)^{N \times N}$
// $N \times N$ matrices where each entry is a $b \times b$ matrix.
for (int ii = 0; ii < N; ii++)
  for (int jj = 0; jj < N; jj++)
    for (int kk = 0; kk < N; kk++)
      for (int i_ = 0; i_ < b; i_++)
        for (int j_ = 0; j_ < b; j_++)
          for (int k_ = 0; k_ < b; k_++) {
             const int i = ii*b + i_;
             const int j = jj*b + j_;
             const int k = kk*b + k_;
             C[i*n + j] = C[i*n + j] + A[i*n + k] * B[k*n + j];
          }
\end{minted}
  \end{onlyenv}
\end{frame}

\begin{frame}
  \frametitle{What did that do to the data movement?}
  \vskip -15pt
  \begin{align*}%
    m &= N n^\mathsf{2} &\text{each block of $B$ is read $N^\mathsf{3}$ times%
      % $\Rightarrow N^\mathsf{3} b^\mathsf{2} = N^\mathsf{3} (n/N)^\mathsf{2} = N n^\mathsf{2}$
        }\\
      &+ N n^\mathsf{2} &\text{each block of $A$ is read $N^\mathsf{3}$ times}\\
      &+ \mathsf{2} n^\mathsf{2} &\text{each block of $C$ is read once and written
        once}\\
      &= \mathsf{2 n^2(N+1)}
  \end{align*}
  Hence
  \begin{equation*}
    \lim_{n\to\infty} \textcolor{MidnightBlue}{q} =
    \frac{\textcolor{MidnightBlue}{f}}{\textcolor{MidnightBlue}{m}} =
    \frac{\mathsf{2} n^\mathsf{3}}{\mathsf{2}n^\mathsf{2}\mathsf{(N + 1)}} \approx
    \frac{n}{N} = b \gg \mathsf{2}
  \end{equation*}

  \pause

  \structure{Limit on $b$}: still must still fit in fast memory.


% \midrule

% \small Lam, Rothberg, and Wolf.
% \emph{The Cache Performance and Optimization of Blocked Algorithms} (1991)

\end{frame}

\begin{frame}
  \frametitle{From model to machine characteristics}
  \begin{itemize}
  \item If algorithm is ``fast'' when $T \ge \mathsf{50}\%$ peak, then
    \begin{equation*}
      \textcolor{MidnightBlue}{f}\; \textcolor{BrickRed}{t_f}
      \left(
        \mathsf{1} +
        \frac{\textcolor{BrickRed}{t_m}}
        {\mathsf{\textcolor{MidnightBlue}\;\textcolor{BrickRed}{t_f}}}
        \frac{\mathsf{1}}{\textcolor{MidnightBlue}{q}}
      \right)
      \le \mathsf 2\;
      \textcolor{MidnightBlue}{f}\; \textcolor{BrickRed}{t_f}
      \Leftrightarrow
      \frac{\textcolor{BrickRed}{t_m}}
      {\mathsf{\textcolor{MidnightBlue}\;\textcolor{BrickRed}{t_f}}}
      \frac{\mathsf{1}}{\textcolor{MidnightBlue}{q}}
      \le \mathsf{1}
      \Leftrightarrow \textcolor{MidnightBlue}{q} \ge
      \frac{\textcolor{BrickRed}{t_m}}
      {\mathsf{\textcolor{MidnightBlue}\;\textcolor{BrickRed}{t_f}}}
    \end{equation*}
  \item For $\textcolor{BrickRed}{t_m} = \mathsf{25}$,
    $\textcolor{BrickRed}{t_f} = \mathsf{1}$
    \Rightarrow $b \approx q \ge \mathsf{25}$.
  \item To hold all three $b \times b$ matrices in cache we need
    \begin{equation*}
      \mathsf{3 b^2 = 3 \cdot \mathsf{25}^2 = 1875} \text{ doubles }
      \approx \mathsf{14.6}\text{KB of fast memory}
    \end{equation*}
  \item This is smaller than L1, but too large for registers.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Is this the best we can do?}
  \begin{block}{Hong and Kung (1981)}
    Any reorganization of this algorithm using only \emph{associativity} has
    \vskip -10pt
    \begin{equation*}
      q = \mathcal{O}(\sqrt{M_\text{fast}})
    \end{equation*}
    \vskip -2pt
    and the number of data elements moved (slow $\Leftrightarrow$ fast) is
    \vskip -10pt
    \begin{equation*}
      \Omega\left(\frac{n^\mathsf{3}}{\sqrt{M_\text{fast}}}\right)
    \end{equation*}
    \vskip -2pt
  \end{block}
  \begin{itemize}
  \item Exact values for the bounds are not known
  \item Best bounds by Smith and van de Geijn (2017) %arXiv: 1702.02017
  \item GotoBLAS/OpenBLAS approach approaches these bounds
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Exercise 8: tiled matrix--matrix multiplication}
  \begin{enumerate}[itemsep=8pt]
  \item Split into small groups
  \item Download the code (three versions, one source)
  \item Measure Flop rate as matrix size changes
  \item Try different tile sizes
  \item Ask questions!
  \end{enumerate}
\end{frame}

\end{document}

\begin{frame}
  \frametitle{Is this the best we can do?}
  \begin{center}
    \begin{tikzpicture}
      \pgfplotstableset{create on use/flops/.style={
          create col/expr={1e-9*\thisrow{FLOP}/\thisrow{TIME}}}};
      \begin{axis}[height=0.7\textheight,
        xlabel near ticks,
        xlabel={Matrix size},
        ylabel near ticks,
        ylabel={GFlop/s},
        legend pos=outer north east,
        legend style={fill=bgcolor}]
        \addplot+ table[x=N, y=flops] {../figures/gemm-basic.dat};
        \addlegendentry{Triple loop};
        \addplot+ table[x=N, y=flops] {../figures/gemm-tiled.dat};
        \addlegendentry{Tiled};
        \addplot+ table[x=N, y=flops] {../figures/gemm-tiled-packed.dat};
        \addlegendentry{Tiled packed};
        \addplot+ [domain=0:3072, mark=none, line width=2] {57.6/2};
        \addlegendentry{Model};
      \end{axis}
    \end{tikzpicture}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Is this the best we can do?}
  \begin{center}
    \begin{tikzpicture}
      \pgfplotstableset{create on use/flops/.style={
          create col/expr={1e-9*\thisrow{FLOP}/\thisrow{TIME}}}};
      \begin{axis}[height=0.7\textheight,
        xlabel near ticks,
        xlabel={Matrix size},
        ylabel near ticks,
        ylabel={GFlop/s},
        legend pos=outer north east,
        legend style={fill=bgcolor}]
        \addplot+ table[x=N, y=flops] {../figures/gemm-basic.dat};
        \addlegendentry{Triple loop};
        \addplot+ table[x=N, y=flops] {../figures/gemm-tiled.dat};
        \addlegendentry{Tiled};
        \addplot+ table[x=N, y=flops] {../figures/gemm-tiled-packed.dat};
        \addlegendentry{Tiled packed};
        \addplot+ [domain=0:3072, mark=none, line width=2] {57.6/2};
        \addlegendentry{Model};

        \addplot+ table[x=N, y=flops] {../figures/gemm-openblas.dat};
        \addlegendentry{OpenBLAS};

        \addplot+ [domain=0:3072, mark=none, line width=2] {57.6};
        \addlegendentry{Machine peak};
      \end{axis}
    \end{tikzpicture}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{What accounts for this difference?}
  \begin{itemize}
  \item Managed to get big matrices to behave like small ones with
    naive code.
  \item[$\Rightarrow$] reaching in-cache performance of the starting
    point.
  \item For better results, need to
    \begin{enumerate}
    \item Block for registers and all levels of cache
    \item Perform data-layout transformation to promote (better) vectorisation
    \end{enumerate}
  \item Will look more at data layout transforms next time.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Summary}
  \begin{itemize}
  \item Loop tiling can \emph{significantly} improve performance of
    nested loops.
  \item Particularly important to exploit data reuse.
  \item For the ``last mile'' we have to do more. Mostly the same
    idea, but thinking hard about data layout and explicit
    vectorisation.
  \item Simple models can be used to motivate whether things are worth trying.
  \end{itemize}
\end{frame}
\end{document}


\begin{frame}
  \frametitle{From model to machine characteristics}
  \begin{itemize}
  \item If algorithm is ``fast'' when $T \ge \mathsf{50}\%$ peak, then
    \begin{equation*}
      f t_f \left(1 + \frac{t_m}{t_f}\frac{1}{q}\right) \le 2 t_f f \Leftrightarrow \frac{t_m}{t_f}\frac{1}{q} \le 1
      \Leftrightarrow q \ge \frac{t_m}{t_f}
    \end{equation*}
  \item Again, approximate $t_m = \mathsf{25}$, $t_f = $1
  \item[$\Rightarrow$] $b \approx q \ge \mathsf{25}$.
  \item Need to hold all three $b \times b$ matrices in cache
  \item Need space for $3 b^2 = 3 \cdot \mathsf{25^2} = 1875$
    matrix \emph{entries}, approximately $\mathsf{14.6}$KB of fast memory
    $M_\text{fast}$.
  \item This is smaller than L1, but larger than fits in registers.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Is this the best we can do?}
  \begin{theorem}{Hong and Kung (1981)}
    Any reorganization of this algorithm that only exploits
    \emph{associativity} has
    \begin{equation*}
      q = \mathcal{O}(\sqrt{M_\text{fast}})
    \end{equation*}
    and the number of data elements moved between slow and fast memory
    is
    \begin{equation*}
      \Omega\left(\frac{n^3}{\sqrt{M_\text{fast}}}\right)
    \end{equation*}
  \end{theorem}

  \begin{itemize}
  \item Exact values for the bounds are not known, the best bounds are
    provided by Smith and van de Geijn (2017) \texttt{arXiv:
      1702.02017 [cs.CC]}
  \item The GotoBLAS/OpenBLAS approach approaches these bounds.
  \end{itemize}
\end{frame}
\begin{frame}
  \frametitle{What did that do to the data movement?}
  \begin{align*}
    m &= N n^2 \quad \text{each block of $B$ is read $N^3$ times
        $\Rightarrow N^3 b^2 = N^3 (n/N)^2 = N n^2$}\\
      &+ N n^2 \quad \text{each block of $A$ is read $N^3$ times}\\
      &+ 2 n^2 \quad \text{each block of $C$ is read once and written
        once}\\
      &= 2n^2(N+1)
  \end{align*}
  Hence
  \begin{equation*}
    \lim_{n\to\infty} q = \frac{f}{m} = \frac{2 n^3}{2n^2(N + 1)} =
    \frac{n}{N} = b
  \end{equation*}


  \begin{itemize}
  \item $b \gg 2$ so much better than previously. Can improve
    performance by increasing $b$ \emph{as long as blocks still fit in
      fast memory!}
  \item Detailed analysis of blocked algorithms in Lam, Rothberg, and
    Wolf \emph{The Cache Performance and Optimization of Blocked
      Algorithms} (1991)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Exercise 8: tiled matrix--matrix multiplication}
  \begin{itemize}
  \item I provide some sample code that implements this scheme
  \item[$\Rightarrow$] Exercise 8.
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Is this the best we can do?}
  \begin{center}
    \begin{tikzpicture}
      \pgfplotstableset{create on use/flops/.style={
          create col/expr={1e-9*\thisrow{FLOP}/\thisrow{TIME}}}};
      \begin{axis}[height=0.7\textheight,
        xlabel near ticks,
        xlabel={Matrix size},
        ylabel near ticks,
        ylabel={GFlop/s},
        legend pos=outer north east,
        legend style={fill=bgcolor}]
        \addplot+ table[x=N, y=flops] {../figures/gemm-basic.dat};
        \addlegendentry{Triple loop};
        \addplot+ table[x=N, y=flops] {../figures/gemm-tiled.dat};
        \addlegendentry{Tiled};
        \addplot+ table[x=N, y=flops] {../figures/gemm-tiled-packed.dat};
        \addlegendentry{Tiled packed};
        \addplot+ [domain=0:3072, mark=none, line width=2] {57.6/2};
        \addlegendentry{Model};
      \end{axis}
    \end{tikzpicture}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Is this the best we can do?}
  \begin{center}
    \begin{tikzpicture}
      \pgfplotstableset{create on use/flops/.style={
          create col/expr={1e-9*\thisrow{FLOP}/\thisrow{TIME}}}};
      \begin{axis}[height=0.7\textheight,
        xlabel near ticks,
        xlabel={Matrix size},
        ylabel near ticks,
        ylabel={GFlop/s},
        legend pos=outer north east,
        legend style={fill=bgcolor}]
        \addplot+ table[x=N, y=flops] {../figures/gemm-basic.dat};
        \addlegendentry{Triple loop};
        \addplot+ table[x=N, y=flops] {../figures/gemm-tiled.dat};
        \addlegendentry{Tiled};
        \addplot+ table[x=N, y=flops] {../figures/gemm-tiled-packed.dat};
        \addlegendentry{Tiled packed};
        \addplot+ [domain=0:3072, mark=none, line width=2] {57.6/2};
        \addlegendentry{Model};

        \addplot+ table[x=N, y=flops] {../figures/gemm-openblas.dat};
        \addlegendentry{OpenBLAS};

        \addplot+ [domain=0:3072, mark=none, line width=2] {57.6};
        \addlegendentry{Machine peak};
      \end{axis}
    \end{tikzpicture}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{What accounts for this difference?}
  \begin{itemize}
  \item Managed to get big matrices to behave like small ones with
    naive code.
  \item[$\Rightarrow$] reaching in-cache performance of the starting
    point.
  \item For better results, need to
    \begin{enumerate}
    \item Block for registers and all levels of cache
    \item Perform data-layout transformation to promote (better) vectorisation
    \end{enumerate}
  \item Will look more at data layout transforms next time.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Summary}
  \begin{itemize}
  \item Loop tiling can \emph{significantly} improve performance of
    nested loops.
  \item Particularly important to exploit data reuse.
  \item For the ``last mile'' we have to do more. Mostly the same
    idea, but thinking hard about data layout and explicit
    vectorisation.
  \item Simple models can be used to motivate whether things are worth trying.
  \end{itemize}
\end{frame}
\end{document}
